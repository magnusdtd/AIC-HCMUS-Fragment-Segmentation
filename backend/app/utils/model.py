import os, requests, tarfile
from ultralytics import YOLO
import zipfile
import numpy as np
import PIL

class Model:
  
  def __init__(self):
    self.OVERLAID_MASK_PATH = "./mask"
    self.MODEL_PATH = "./model"

    # Set your Kaggle username and API key
    KAGGLE_USERNAME = os.getenv("KAGGLE_USERNAME", "magnusdtd")
    KAGGLE_KEY = os.getenv("KAGGLE_KEY", "3fbae224a666c4940cfda19ef24cc176")
    KAGGLE_URL = os.getenv("KAGGLE_URL", "https://www.kaggle.com/api/v1/models/magnusdtd/gdgoc_hcmus_aic-yolov11m-ht/pyTorch/default/3/download")
    download_path = os.path.expanduser("./model.tar.gz")
    extract_path = os.path.expanduser("./model_extracted")

    # Step 1: Download the file
    response = requests.get(
        KAGGLE_URL,
        auth=(KAGGLE_USERNAME, KAGGLE_KEY),
        stream=True,
        allow_redirects=True
    )

    if response.status_code == 200:
        with open(download_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        print(f"‚úÖ Model downloaded to {download_path}")

        # Step 2: Extract the .tar.gz file
        os.makedirs(extract_path, exist_ok=True)
        with tarfile.open(download_path, "r:gz") as tar:
            tar.extractall(path=extract_path)
        print(f"‚úÖ Model extracted to {extract_path}")

            # Step 3: Delete the .tar.gz file
        os.remove(download_path)
        print(f"üóëÔ∏è  Removed archive file: {download_path}")

    else:
        print(f"‚ùå Failed to download model: {response.status_code}")
        print(response.text)


    self.model = YOLO(f"{extract_path}/yolov11m_finetuned.pt")
    self.model.info()
    self.model.to("cpu")

  def preprocess(img):
    pass

  def postprocess(model_result):
    pass

  def get_overlaid_mask(img, binary_mask):
    pass

  def get_volume(img, binary_mask):
    pass

  async def predict(self, img: PIL.Image, conf: float=0.5, iou: float=0.5, save: bool=False):
    print("Model trying to inference...")
    try:
        results = self.model.predict(source=img, conf=conf, iou=iou, save=save)
        if results[0].masks is None:
            print("No masks were generated by the model.")
            return None
        masks = results[0].masks.data.cpu().numpy()

        print("Mask shape: ", masks.shape)
        
    except Exception as e:
        print(f"Error during prediction: {e}")
        return None
    
    volume_data = np.random.normal(loc=0.0, scale=1.0, size=masks.shape[0])
    is_calibrated = False
    print("Model inference successfully")
    return (masks, volume_data, is_calibrated)

model = Model()
